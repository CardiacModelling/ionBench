{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d047e3-18d0-4931-904a-39ed9b8adfc2",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "This guide explains how to use **ionBench**. It gives practical advice on setting up and editting problems classes and running optimisers. If you want more theoretical information, such as the what the performance metrics are, check out the **introduction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8ab68e-e916-42e3-a5a9-ba37386acc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ionbench\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b6c28-da5b-4336-af52-1b20a8f73502",
   "metadata": {},
   "source": [
    "## Benchmarkers and Test Problems\n",
    "Each of the benchmarker problem classes are loaded in a similar way. They may take a few seconds to initialise while they compile the Myokit simulation objects to run the models. Typically you would only need one benchmarker at once, here we will use the staircase Hodgkin-Huxley benchmarker, but the functions to load the other benchmarkers are shown below, just commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4814dbd7-89b1-4425-9b4b-31d2da399faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Hodgkin-Huxley IKr benchmark\n",
      "Benchmarker initialised\n"
     ]
    }
   ],
   "source": [
    "hh = ionbench.problems.staircase.HH_Benchmarker()\n",
    "# mm = ionbench.problems.staircase.MM_Benchmarker()\n",
    "# ikr = ionbench.problems.loewe2016.ikr()\n",
    "# ikur = ionbench.problems.loewe2016.ikur()\n",
    "# ina = ionbench.problems.moreno2016.ina()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa051e4-604b-42aa-b8d0-ae9518fcdab3",
   "metadata": {},
   "source": [
    "### Sampling Parameters\n",
    "Now that we have a problem initialised, we can take a look at some of the functions we can use with it.\n",
    "The `.sample()` method will randomly sample a set of parameters in a region defined for each problem. It is the main method for generating parameters. The sample method for each function also has an optional input `n`. This allows you to generate more than one parameter vector, returning a list of parameter vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633311c5-8e84-47ed-baab-b9a2dfeae0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled parameters: \n",
      "[3.27099332e-04 7.14759653e-02 2.73881342e-05 2.87101306e-02\n",
      " 7.50206334e-02 1.06943147e-02 6.59648083e-03 3.72709626e-02\n",
      " 2.15051015e-01]\n",
      "Sampling more than one parameter vector:\n",
      "[array([2.02081103e-04, 1.02565678e-01, 4.31597242e-05, 3.84095094e-02,\n",
      "       4.74350888e-02, 1.05226870e-02, 2.98765504e-03, 1.81402225e-02,\n",
      "       2.20044519e-01]), array([2.29416700e-04, 9.21521232e-02, 3.09710391e-05, 7.77320552e-02,\n",
      "       7.80573329e-02, 5.79896950e-03, 7.41541395e-03, 2.58995372e-02,\n",
      "       2.02618011e-01]), array([1.33324099e-04, 7.22165608e-02, 2.86188689e-05, 2.87737245e-02,\n",
      "       5.45074177e-02, 5.91460153e-03, 5.01938196e-03, 3.26562181e-02,\n",
      "       1.76964077e-01])]\n"
     ]
    }
   ],
   "source": [
    "print('Sampled parameters: ')\n",
    "print(hh.sample())\n",
    "print('Sampling more than one parameter vector:')\n",
    "print(hh.sample(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8456af1-834e-4ad6-a456-b9cc5ade437e",
   "metadata": {},
   "source": [
    "### Cost Functions\n",
    "Now that we have seen how to sample parameters, we can use the benchmarker to see how good sampled parameter are. \n",
    "Each benchmarker has a `.cost()` method which takes an input of a set of parameters and will simulate the model with those parameters, compare against the data stored in `hh.data` and calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c46a403-6a77-4059-aa27-e01877da6fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled parameters:\n",
      "[2.53927936e-04 6.22859804e-02 2.61220127e-05 4.11729521e-02\n",
      " 6.66611973e-02 7.82837303e-03 3.45436313e-03 2.26625694e-02\n",
      " 1.02735647e-01]\n",
      "Cost of sampled parameters:\n",
      "0.2986688787651777\n"
     ]
    }
   ],
   "source": [
    "param = hh.sample()\n",
    "print('Sampled parameters:')\n",
    "print(param)\n",
    "print('Cost of sampled parameters:')\n",
    "print(hh.cost(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb700772-3d36-49bd-8d26-a4037912283b",
   "metadata": {},
   "source": [
    "Sometimes we don't want to know the RMSE cost and instead want a vector of residuals. Luckily there are methods in the benchmarker for both residuals and squared residuals. These are sometimes required by certain optimisers such as scipy's least squares optimisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c72c2e-fc91-47fd-904c-35f0075a64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals of sampled parameters:\n",
      "[ 0.00524567 -0.00674937 -0.00627976 ...  0.03588397  0.02150199\n",
      "  0.03188496]\n",
      "Squared residuals of sampled parameters:\n",
      "[2.75170681e-05 4.55540567e-05 3.94354054e-05 ... 1.28765897e-03\n",
      " 4.62335619e-04 1.01665045e-03]\n"
     ]
    }
   ],
   "source": [
    "print('Residuals of sampled parameters:')\n",
    "print(hh.signed_error(param))\n",
    "print('Squared residuals of sampled parameters:')\n",
    "print(hh.squared_error(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb813a49-6002-4dba-b285-7d256963ca03",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "There are also some other generally useful functions in the benchmarkers. Each benchmarker has a function which returns the number of parameter in its model, called `.n_parameters()`. Each benchmarker also stores a name variable under `._name`. Try to keep the use of `._name` as limited as possible but sometimes it may be necessary to include problem-specific features, for example, the modifications use `._name` to identify the bounds for the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95458d6b-41e2-4c2e-9e53-94621678db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter in the model:\n",
      "9\n",
      "Name of the benchmarker:\n",
      "staircase.hh\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameter in the model:')\n",
    "print(hh.n_parameters())\n",
    "print('Name of the benchmarker:')\n",
    "print(hh._name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fac929-53fc-4fdd-9ec1-d28d8676e6a7",
   "metadata": {},
   "source": [
    "The names for the benchmarker problems are:\n",
    "* staircase.hh\n",
    "* staircase.mm\n",
    "* loewe2016.ikr\n",
    "* loewe2016.ikur\n",
    "* moreno2016.ina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bb8e0-945d-4cf5-89fc-c7fdc8d7fbaa",
   "metadata": {},
   "source": [
    "## Transforms and Bounds\n",
    "It is possible to apply transforms or bounds in the benchmarkers. These will automatically update the benchmarkers `.sample()` method to account for these transforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973a461-6891-454e-af4d-64f349dc670a",
   "metadata": {},
   "source": [
    "### Log Transforms\n",
    "You can apply log transforms for specific parameters on a benchmarker object. The parameters which are log transformed are stored in the `._logTransformParams` variable in the benchmarker as a list of bools. This can be changed, and therefore log transform some parameters, by calling the `.log_transform method()`. By default, this method will log transform all parameters unless the optional input whichParams is set as a list of bools, of length n_parameters, where `True` is a parameter to log transform, and `False` is a parameter to not log transform. \n",
    "\n",
    "Beware useing log transforms for the Loewe 2016 problems. Since the sampler can return negative parameters you need to be careful with which parameters to log transform. Each benchmarker has a `.standardLogTransform` variable which stores typical parameters that could be log transformed, especially useful for the Loewe problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e6db44-1557-45f7-8587-32b6f6e8aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled parameters:\n",
      "[1.23866405e-04 6.96115152e-02 2.86686297e-05 3.55937211e-02\n",
      " 4.74798803e-02 6.64350768e-03 6.51720976e-03 2.94101524e-02\n",
      " 1.85204628e-01]\n",
      "By default, no parameters are log transformed\n",
      "[False, False, False, False, False, False, False, False, False]\n",
      "Standard parameters to log transform for HH benchmarker:\n",
      "[True, False, True, False, True, False, True, False, False]\n",
      "The parameters now log transformed:\n",
      "[True, False, True, False, True, False, True, False, False]\n",
      "Sampled log transformed parameters:\n",
      "[-8.84088173e+00  8.17745527e-02 -1.01249725e+01  3.66044496e-02\n",
      " -2.62599325e+00  8.25945715e-03 -5.91594429e+00  1.92344057e-02\n",
      "  1.09858746e-01]\n"
     ]
    }
   ],
   "source": [
    "print('Sampled parameters:')\n",
    "print(hh.sample())\n",
    "print('By default, no parameters are log transformed')\n",
    "print(hh._logTransformParams)\n",
    "print('Standard parameters to log transform for HH benchmarker:')\n",
    "print(hh.standardLogTransform)\n",
    "hh.log_transform(whichParams = hh.standardLogTransform)\n",
    "print('The parameters now log transformed:')\n",
    "print(hh._logTransformParams)\n",
    "print('Sampled log transformed parameters:')\n",
    "print(hh.sample())\n",
    "hh.log_transform(whichParams = [False]*hh.n_parameters()) #Revert log transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d966c6b-24cc-43f6-8f31-24f5618b81ee",
   "metadata": {},
   "source": [
    "### Scale Factors\n",
    "You can also apply scale factor transforms. This will set the default or true rates to be a vector of all ones and recognise parameters as factors to these. For example, since the HH staircase sampler operates in a +-50% region around the true parameter values, after scale factor transforming, it will operate in the interval \\[0.5,1.5\\] for all parameters. \n",
    "\n",
    "Scale factor transformations can only be applied to all parameters at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf10c80b-0fd1-44d6-9271-ffc42558adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled parameters:\n",
      "[2.79576012e-04 4.19080266e-02 3.04561459e-05 5.14163649e-02\n",
      " 9.11273100e-02 1.19505999e-02 5.62768498e-03 4.35647834e-02\n",
      " 1.34905337e-01]\n",
      "Sampled parameters when applying scale factors:\n",
      "[0.93744763 0.54944712 1.27140554 1.10550997 0.50140821 0.98123076\n",
      " 0.91169524 1.17866956 1.11098499]\n"
     ]
    }
   ],
   "source": [
    "print('Sampled parameters:')\n",
    "print(hh.sample())\n",
    "print('Sampled parameters when applying scale factors:')\n",
    "hh._useScaleFactors = True\n",
    "print(hh.sample())\n",
    "hh._useScaleFactors = False #Revert scale factor transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f27eb-3387-462c-bbb2-c9c3dc4b07fa",
   "metadata": {},
   "source": [
    "### Input and Original Parameter Spaces\n",
    "When using transforms, it may be useful to map between different parameter spaces. We define the input space as including any transformations applied to the benchmarker, while the original parameter space is the one used in model simulations. Each benchmarker has two helper functions which map between these parameter spaces. These are used frequently in the inner-workings of **ionBench**.\n",
    "\n",
    "Generally, optimisers will work exclusively in input parameter space. The cost functions should only be evaluated in input spaced parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc2c21e-7a6e-4eed-8f97-ef4b872816a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled parameters are given in input parameter space:\n",
      "[1.39154003 0.92836358 1.43904006 1.06178831 1.37631765 1.20179668\n",
      " 1.44692994 0.58892932 1.34501435]\n",
      "When mapped to the original parameter space:\n",
      "[3.14488047e-04 6.48926144e-02 4.96468822e-05 5.79948777e-02\n",
      " 1.20152531e-01 1.07080084e-02 7.45168918e-03 1.85983880e-02\n",
      " 2.04980187e-01]\n",
      "Input space of these parameters will return the original sampled parameters:\n",
      "[1.39154003 0.92836358 1.43904006 1.06178831 1.37631765 1.20179668\n",
      " 1.44692994 0.58892932 1.34501435]\n"
     ]
    }
   ],
   "source": [
    "hh._useScaleFactors = True #Apply a transform\n",
    "print('Sampled parameters are given in input parameter space:')\n",
    "param = hh.sample()\n",
    "print(param)\n",
    "print('When mapped to the original parameter space:')\n",
    "output_space = hh.original_parameter_space(param)\n",
    "print(output_space)\n",
    "print('Input space of these parameters will return the original sampled parameters:')\n",
    "print(hh.input_parameter_space(output_space))\n",
    "hh._useScaleFactors = False # Revert scale factor transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10663027-0552-4880-ac85-51f9802eb73b",
   "metadata": {},
   "source": [
    "### Parameter Bounds\n",
    "Parameter bounds can be applied by using the `.add_bounds()` method. It takes inputs of a list of two elements, a list of lower bounds and a list of upper bounds. If the cost function (or its alternatives) are called with parameters that are outside of these bounds, an infinite cost will be returned. \n",
    "\n",
    "To avoid setting upper or lower bounds on some parameters, `np.inf` and `-np.inf` can be used.\n",
    "\n",
    "To determine whether or not bounds are active (or to disable them), you can read (or set to `False`) the variable `._bounded` in the benchmarker problem object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e29294-6feb-4374-a11f-5600471e0deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default the benchmarker is not bounded:\n",
      "False\n",
      "When a parameter is out of bounds the cost will be infinite\n",
      "inf\n",
      "Bounds can be disabled by setting the _bounded variable\n",
      "Now the cost will be calculated with the negative parameter\n",
      "7.511628486815581\n"
     ]
    }
   ],
   "source": [
    "print('By default the benchmarker is not bounded:')\n",
    "print(hh._bounded)\n",
    "hh.add_bounds([[0]*hh.n_parameters(), [np.inf]*hh.n_parameters()]) #Add lower bounds at 0 and no upper bounds\n",
    "param = hh.sample()\n",
    "param[-1] = -1 #Parameter out of bounds \n",
    "\"\"\"\n",
    "(Note: The last parameter is the conductance, this was specifically chosen since negative \n",
    "parameters can easy cause a model solve to fail)\n",
    "\"\"\"\n",
    "print('When a parameter is out of bounds the cost will be infinite')\n",
    "print(hh.cost(param))\n",
    "print('Bounds can be disabled by setting the _bounded variable')\n",
    "hh._bounded = False\n",
    "print('Now the cost will be calculated with the negative parameter')\n",
    "print(hh.cost(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39b43c-7362-4ccc-af67-50a77360f896",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "Sometimes you might want to apply transforms to multiple different benchmarkers. In that case, it may be best to generate an modification. A modification is an object which stores settings for bounds, log transforms and scale factor transforms. \n",
    "\n",
    "Each modification stores three strings from when it is generated. These strings are the settings for log transforms, bounds and scale factors. \n",
    "\n",
    "The available settings for log transforms are `'None'`, `'Standard'`, `'Full'`, or `'Custom'`.\n",
    "\n",
    "The available settings for bounds are `'None'`, `'Positive'`, `'Sampler'`, or `'Custom'`.\n",
    "\n",
    "The available settings for scale factors are `'on'` or `'off'`.\n",
    "\n",
    "Once the modification has been constructed and the settings have been specified, the `.apply()` method can be used to apply these settings to a benchmarker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323228bc-c4c5-466c-8eef-29f1cf0777af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The benchmarker is not bounded before\n",
      "False\n",
      "The benchmarker is bounded after applying the modification\n",
      "True\n",
      "The sampler bounds are different for each problem\n",
      "Lower bounds:\n",
      "[1.130e-04 3.495e-02 1.725e-05 2.731e-02 4.365e-02 4.455e-03 2.575e-03\n",
      " 1.579e-02 7.620e-02]\n",
      "Upper bounds:\n",
      "[3.3900e-04 1.0485e-01 5.1750e-05 8.1930e-02 1.3095e-01 1.3365e-02\n",
      " 7.7250e-03 4.7370e-02 2.2860e-01]\n"
     ]
    }
   ],
   "source": [
    "mod = ionbench.modification.Modification(bounds = 'Sampler') #Generate a modification with sampler bounds and default transforms (no log and scale factor off)\n",
    "print('The benchmarker is not bounded before')\n",
    "print(hh._bounded)\n",
    "mod.apply(hh)\n",
    "print('The benchmarker is bounded after applying the modification')\n",
    "print(hh._bounded)\n",
    "print('The sampler bounds are different for each problem')\n",
    "print('Lower bounds:')\n",
    "print(hh.lb)\n",
    "print('Upper bounds:')\n",
    "print(hh.ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f21ac1-9778-420d-94eb-946b107d6369",
   "metadata": {},
   "source": [
    "There are also a range of predefined modifications from different papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5555646-6c90-4ffc-9d8c-622863a3253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The settings for the Clerx 2019 modification are:\n",
      "{'log transform': 'Standard', 'bounds': 'Sampler', 'scale factors': 'off'}\n"
     ]
    }
   ],
   "source": [
    "mod = ionbench.modification.Clerx2019()\n",
    "print('The settings for the Clerx 2019 modification are:')\n",
    "print(mod.dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caf9ad-bf6f-4ff9-ae3e-12f9dd8fb429",
   "metadata": {},
   "source": [
    "## Optimisers\n",
    "There are a variety of optimisers included in **ionBench** and if you are using it, its likely that you would like to test your own optimiser. If you do wish to test your own optimiser, it is important to understand how the optimisers are formatted in **ionBench**. \n",
    "\n",
    "The main thing to note is that each optimiser has a run function which has only one required input, a benchmarker object. The optimiser will then use this benchmarker object to find its bounds (if your optimiser has addition features for bounds such as ensuring gradient calculations are inside parameter bounds), use its `.sample()` method to get parameter values and use its `.cost()` method to check the performance of those parameters. Other inputs can be included, it's recommended to include an optional initial point arguement named `x0`, but all non-benchmarker inputs should be optional (If no initial point is specified, the optimiser should use a sampled point).\n",
    "\n",
    "Another detail, although not one you need to account for to measure the performance of your own optimisers, is that each optimiser has an associated modification class that can be retrieved using the `get_modification()` function.\n",
    "\n",
    "Below we retrieve the modification for the LM (Levenberg Marquardt) scipy optimiser (an empty modification with no settings), apply it to a benchmarker, and run the lm scipy optimiser on the benchmarker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa26e5-2723-4a70-9cfd-8538b5616344",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ionbench.optimisers.scipy_optimisers.lm_scipy.get_modification()\n",
    "mod.apply(hh)\n",
    "hh.reset() #Don't worry about this yet\n",
    "out = ionbench.optimisers.scipy_optimisers.lm_scipy.run(hh)\n",
    "print('Fitted parameters are:')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460dc5bf-421d-4262-8db4-b2eb8440bd26",
   "metadata": {},
   "source": [
    "Once the optimisation is complete, the optimiser calls `hh.evaluate(parameters)` with the fitted parameters. This function prints the performance metrics for this final point as well as the performance metrics when the optimiser converged. It then plots the performance metrics over time and the model output for the first parameters, the final/fitted parameters, and the data.\n",
    "\n",
    "These plots can be disabled by setting `hh.plotter = False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f862f8-feab-4834-9086-5031176c040a",
   "metadata": {},
   "source": [
    "## Tracker\n",
    "Each benchmarker stores a __Tracker__ object which calculates and stores the performance metrics over time as well as figuring out when the optimiser converged. You shouldn't normally need to interact with this __Tracker__ object but you may wish to save the information from a __Tracker__ and store it to analyse later, for example if you are running an optimiser on a HPC and can't view the figures. You can use the __Tracker__'s `.save()` and `.load()` methods to do exactly that. \n",
    "\n",
    "You may have noticed the line `hh.reset()` in the previous code cell. This resets the __Tracker__ object, since otherwise all the times we called the cost function would have been included in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b12b47-0d38-4c72-95b1-9d592ac57a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'temporary_tracker_file.pickle'\n",
    "print('Number of times the model has been solved: ')\n",
    "print(hh.tracker.solveCount)\n",
    "hh.tracker.save(filename)\n",
    "print('Number of model solves after reset:')\n",
    "hh.reset()\n",
    "print(hh.tracker.solveCount)\n",
    "print('Number of model solves after load:')\n",
    "hh.tracker.load(filename)\n",
    "print(hh.tracker.solveCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727bded-7afc-407e-b7e1-e8bf6aa3af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove temporary file\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1f210-dd90-4f75-b71b-52c3736dd8b4",
   "metadata": {},
   "source": [
    "## Multistart\n",
    "It might be useful to start an optimisation multiple times. This can be done with the multistart function. It takes inputs of an optimisers `.run` function, a benchmarker, a list of initial parameters, and a filename to use for saving the tracker information.\n",
    "\n",
    "Additional keyword arguements, such as hyperparameters to pass into the optimiser can also be passed into the multistart function. \n",
    "\n",
    "The filename will be automatically appended with `'_run%i.pickle'` where `%i` is the index for which of the initial parameters was used for the optimisation.\n",
    "\n",
    "In addition to saving the tracker data and printing the evaluate output (which is done whenever an optimiser is called), the multistart function will also print the fitted parameters for each optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f5b72-e65e-4583-82d7-a345e339dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ionbench.optimisers.scipy_optimisers.lm_scipy.run\n",
    "hh.reset()\n",
    "initParams = hh.sample(3)\n",
    "filename = 'temporary_tracker_files'\n",
    "ionbench.multistart(opt, hh, initParams, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab5209-e02d-4905-9925-9246f858baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename+'_run0.pickle')\n",
    "os.remove(filename+'_run1.pickle')\n",
    "os.remove(filename+'_run2.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
